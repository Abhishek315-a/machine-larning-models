{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMhtl7d4+dtDrQhdlynCRR/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhishek315-a/machine-larning-models/blob/main/Image_Classification_with_Quantization_and_ONNX_Optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Classification with Quantization and ONNX Optimization\n",
        "# ------------------------------------------------------------\n",
        "# Requirements:\n",
        "# pip install torch torchvision onnx onnxruntime numpy pandas matplotlib"
      ],
      "metadata": {
        "id": "DBqE8N9bIsAH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHEi2aEjIIf6",
        "outputId": "ec8a6234-73d9-4d5c-fb6e-faa24e9e73b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.19.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (7.0 kB)\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.23.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (5.29.5)\n",
            "Requirement already satisfied: ml_dtypes in /usr/local/lib/python3.12/dist-packages (from onnx) (0.5.3)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (25.2.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (25.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading onnx-1.19.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m125.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.23.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m107.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, onnx, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnx-1.19.0 onnxruntime-1.23.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision onnx onnxruntime numpy pandas matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import onnx\n",
        "import onnxruntime as ort\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "cC17UiM5JVdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ------------------------------------------------------------\n",
        "# 1. Data Preparation\n",
        "# ------------------------------------------------------------"
      ],
      "metadata": {
        "id": "MpoEIBCYJaGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "testloader = DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = trainset.classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQZmhrtoJbdU",
        "outputId": "7d6304d0-4223-4354-9c90-e2801f2b23d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:13<00:00, 12.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ------------------------------------------------------------\n",
        "# 2. Define Model (ResNet18)\n",
        "# ------------------------------------------------------------"
      ],
      "metadata": {
        "id": "ceukZrPqJiOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "model = torchvision.models.resnet18(pretrained=False, num_classes=10)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68vG9QYMJllS",
        "outputId": "fde70517-8c46-4c57-b293-1de2f7afdb67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ------------------------------------------------------------\n",
        "# 3. Training\n",
        "# ------------------------------------------------------------"
      ],
      "metadata": {
        "id": "NYSG4oi9Jpv0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "def train_model(epochs=2):  # keep small epochs for demo\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(trainloader):.4f}\")\n",
        "\n",
        "train_model(epochs=2)  # change to higher epochs for better accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rD33yFTJqk0",
        "outputId": "67628ffb-69f1-4973-fd04-dcea34b53d85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/2], Loss: 1.3656\n",
            "Epoch [2/2], Loss: 0.9594\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ------------------------------------------------------------\n",
        "# 4. Evaluate PyTorch Model\n",
        "# ------------------------------------------------------------"
      ],
      "metadata": {
        "id": "jLgKouwaOGSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_pytorch():\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    acc = 100 * correct / total\n",
        "    print(f\"PyTorch FP32 Accuracy: {acc:.2f}%\")\n",
        "    return acc\n",
        "\n",
        "pytorch_acc = evaluate_pytorch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVTW0-t0OG69",
        "outputId": "9a18cd6c-70b3-49b0-c41e-a48e0c8f7d81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch FP32 Accuracy: 64.15%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ------------------------------------------------------------\n",
        "# 5. Export Model to ONNX\n",
        "# ------------------------------------------------------------"
      ],
      "metadata": {
        "id": "bqIRBul6ONPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "onnx_model_path = \"resnet18_cifar10.onnx\"\n",
        "dummy_input = torch.randn(1, 3, 32, 32, device=device)\n",
        "torch.onnx.export(model, dummy_input, onnx_model_path,\n",
        "                  input_names=['input'], output_names=['output'],\n",
        "                  dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}})\n",
        "\n",
        "print(\"ONNX model exported:\", onnx_model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EF2rC4VFONyx",
        "outputId": "bc85a550-37d7-46f0-e99a-f4ba2fee9b28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1043801352.py:3: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
            "  torch.onnx.export(model, dummy_input, onnx_model_path,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ONNX model exported: resnet18_cifar10.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ------------------------------------------------------------\n",
        "# 6. Inference with ONNX Runtime (FP32)\n",
        "# ------------------------------------------------------------"
      ],
      "metadata": {
        "id": "nQAZ2RWHOSet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_numpy(tensor):\n",
        "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
        "\n",
        "ort_session = ort.InferenceSession(onnx_model_path)\n",
        "\n",
        "def evaluate_onnx(session, quantized=False):\n",
        "    correct, total = 0, 0\n",
        "    start = time.time()\n",
        "    for images, labels in testloader:\n",
        "        ort_inputs = {\"input\": to_numpy(images)}\n",
        "        ort_outs = session.run(None, ort_inputs)\n",
        "        preds = np.argmax(ort_outs[0], axis=1)\n",
        "        total += labels.size(0)\n",
        "        correct += (preds == labels.numpy()).sum().item()\n",
        "    end = time.time()\n",
        "\n",
        "    acc = 100 * correct / total\n",
        "    runtime = end - start\n",
        "    mode = \"INT8\" if quantized else \"FP32\"\n",
        "    print(f\"ONNX {mode} Accuracy: {acc:.2f}%, Inference Time: {runtime:.2f}s\")\n",
        "    return acc, runtime\n",
        "\n",
        "onnx_acc_fp32, onnx_time_fp32 = evaluate_onnx(ort_session)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6r23FrPOTJ3",
        "outputId": "b51e690a-56c2-4a45-81bb-5c1b12964e04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ONNX FP32 Accuracy: 64.15%, Inference Time: 12.06s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ------------------------------------------------------------\n",
        "# 7. Quantization (INT8)\n",
        "# ------------------------------------------------------------"
      ],
      "metadata": {
        "id": "L0c8Xg0DOi0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from onnxruntime.quantization import quantize_static, CalibrationDataReader, QuantType\n",
        "import onnxruntime as ort\n",
        "\n",
        "# Custom DataReader for calibration\n",
        "class CIFAR10DataReader(CalibrationDataReader):\n",
        "    def __init__(self, dataloader, num_batches=10):\n",
        "        self.enum_data = None\n",
        "        self.dataloader = dataloader\n",
        "        self.num_batches = num_batches\n",
        "\n",
        "    def get_next(self):\n",
        "        if self.enum_data is None:\n",
        "            inputs = []\n",
        "            count = 0\n",
        "            for images, _ in self.dataloader:\n",
        "                if count >= self.num_batches:\n",
        "                    break\n",
        "                inputs.append({\"input\": images.numpy()})\n",
        "                count += 1\n",
        "            self.enum_data = iter(inputs)\n",
        "        return next(self.enum_data, None)\n",
        "\n",
        "# Calibration\n",
        "calibration_reader = CIFAR10DataReader(testloader, num_batches=10)\n",
        "\n",
        "quantized_model_path = \"resnet18_cifar10_int8.onnx\"\n",
        "quantize_static(\n",
        "    model_input=onnx_model_path,\n",
        "    model_output=quantized_model_path,\n",
        "    calibration_data_reader=calibration_reader,\n",
        "    weight_type=QuantType.QInt8\n",
        ")\n",
        "\n",
        "# Load quantized model\n",
        "ort_session_int8 = ort.InferenceSession(quantized_model_path)\n",
        "onnx_acc_int8, onnx_time_int8 = evaluate_onnx(ort_session_int8, quantized=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHZNWigXOja_",
        "outputId": "4e014d9f-cef1-4d32-a49f-d360a9bbda13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n",
            "WARNING:root:Please consider pre-processing before quantization. See https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ONNX INT8 Accuracy: 63.91%, Inference Time: 22.03s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ------------------------------------------------------------\n",
        "# 8. Model Size Comparison\n",
        "# ------------------------------------------------------------"
      ],
      "metadata": {
        "id": "HU97FS95POM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fp32_size = os.path.getsize(onnx_model_path) / (1024 * 1024)\n",
        "int8_size = os.path.getsize(quantized_model_path) / (1024 * 1024)\n",
        "\n",
        "print(f\"Model Size FP32: {fp32_size:.2f} MB\")\n",
        "print(f\"Model Size INT8: {int8_size:.2f} MB\")\n",
        "print(f\"Size Reduction: {(1 - int8_size/fp32_size)*100:.1f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t64amYgzPO02",
        "outputId": "d5c6942d-0000-401f-8da9-51bb6e2635a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Size FP32: 42.65 MB\n",
            "Model Size INT8: 10.72 MB\n",
            "Size Reduction: 74.9%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ------------------------------------------------------------\n",
        "# 9. Benchmark Summary\n",
        "# ------------------------------------------------------------"
      ],
      "metadata": {
        "id": "KAl1m9djPS85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary = {\n",
        "    \"FP32 Accuracy\": pytorch_acc,\n",
        "    \"ONNX FP32 Accuracy\": onnx_acc_fp32,\n",
        "    \"ONNX INT8 Accuracy\": onnx_acc_int8,\n",
        "    \"FP32 Inference Time (s)\": onnx_time_fp32,\n",
        "    \"INT8 Inference Time (s)\": onnx_time_int8,\n",
        "    \"FP32 Model Size (MB)\": fp32_size,\n",
        "    \"INT8 Model Size (MB)\": int8_size\n",
        "}"
      ],
      "metadata": {
        "id": "B_RggzOlPTdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nBenchmark Summary:\")\n",
        "for k, v in summary.items():\n",
        "    print(f\"{k}: {v}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v31X4PcCPYbl",
        "outputId": "f7826ea2-ba85-4f94-90cc-c03797cfa698"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Benchmark Summary:\n",
            "FP32 Accuracy: 64.15\n",
            "ONNX FP32 Accuracy: 64.15\n",
            "ONNX INT8 Accuracy: 63.91\n",
            "FP32 Inference Time (s): 12.057161331176758\n",
            "INT8 Inference Time (s): 22.029340028762817\n",
            "FP32 Model Size (MB): 42.64553356170654\n",
            "INT8 Model Size (MB): 10.715697288513184\n"
          ]
        }
      ]
    }
  ]
}